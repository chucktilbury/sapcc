# SAPCC
Simple As Possible Compiler Compiler

- [SAPCC](#sapcc)
  - [Introduction](#introduction)
  - [Directives](#directives)
  - [Scanner Specification](#scanner-specification)
    - [Regular expressions](#regular-expressions)
    - [Scanner generator implementation](#scanner-generator-implementation)
    - [File stack](#file-stack)
    - [Scanner tokens](#scanner-tokens)
    - [Scanner API](#scanner-api)
    - [Scanner errors](#scanner-errors)
      - [Compile time errors](#compile-time-errors)
      - [Runtime errors](#runtime-errors)
  - [Parser Specification](#parser-specification)
  - [Rules](#rules)
    - [Rule structure](#rule-structure)
    - [Accessing data inside a rule clause](#accessing-data-inside-a-rule-clause)
    - [Parser generator implementation](#parser-generator-implementation)
    - [Parser errors](#parser-errors)
      - [Compile time errors](#compile-time-errors-1)
      - [Run time errors](#run-time-errors)

----
## Introduction
[top](#sapcc)

This is a simplified compiler compiler that has a similar function as Flex/YACC or Antlr, but greatly simplified. The goal is to create a scanner generator and a parser generator that has a very simple input syntax and good error handling. The output language is C.

What is intended by SAPCC is to have an input syntax that has very few features, but is still able to capture all constructs that are needed to create a full featured parser for a language compiler. Also, it creates output code that is readable by someone who is not very experienced with C. No doubt there are people who are reading this and question if C++ or some other object based language would be better, but I like C and it's completely adequate for this purpose.

The output for a given parser is divided into several files for the actual parser, the scanner, and a syntax tree walker. Also a library of utilities is required to actually build the parser that is generated, as well as the code that actually uses the syntax tree. These are in separate files for ease of use.

The syntax tree that is output is not an "abstract" syntax tree. All of the symbols that are in the source code will be in the syntax tree. It less efficient, but it's more simple to create and understand.

The input file consists of 3 parts. They are directives, parser, and scanner. These parts can be placed in separate files or all in the same file. The order of directives and sections is very flexible. The syntax of the files are also very flexible. In general, spaces are ignored.

All memory allocations that happen are covered by the Bohem garbage collection library. (https://en.wikipedia.org/wiki/Boehm_garbage_collector) No attempt is made to free any memory used, even if a particular set of library routines (such as strings or lists) have the routines present to free memory. The garbage collector makes those routines NOOPs.

Every function in the CC has a trace statement that can be activated using the verbosity directive.

One extended goal is to use DOT notation (from Graphiz) to make balloon syntax drawings of the input that was submitted to the parser for analysis. That will be done after the parser generator is working reasonably well.

## Directives
[top](#sapcc)

A directive is an entry in the file that controls how the input is used and how the output is generated. All aspects of the input file are controled by directives. These directives apply to both the parser and the scanner generators.

- ``%verbosity number`` - This controls how much status is output on the terminal as the input is parsed and the output is emitted. Valid values are a counting numbers from zero (0) for no output except for actual errors and fiffty (50) for almost every single action that the generator takes.
- ``%name string`` - This is the optional base name of the files. The default file names are parser.c, parser.h, scanner.c, scanner.h, syntax.c, syntax.h, and parser.a. If the name is found in any of the input files, then it is prepended to the default name. For example, if the name is "asdf" then the parser header file will be named "asdf_parser.h".
- ``%prefix string`` - This is the optional prefix for global symbols generated by the system. For example, the default name for the parser is "parser". If this directive is present and it's value is "asdf" then the global symbol will become "asdf_parser".
- ``%syntax { C code }`` - This is custom code to be used instead of the default syntax error handler. A syntax error happens when the parser cannot parse the input. Errors that are generated by the parser generator and the scanner generator are generated internally.
- ``%code { C code }`` - This is custom code that is added to the beginning of the syntax module and is intended to support traversing the syntax tree. This is the interface into the actual parsed tree. It is intended that callbacks will be defined here that will interface to more code that implements the actual parser. Multiple code blocks can be specified and they will simply be concatinated in the order in which they are encountered in the parser specification.
- ``%include string`` - This is includes another file into the current file. This file is read exactly as if it is part of the current file.
- ``%scanner { scanner spec }`` - This is the scanner specification. All of the terminal symbols that are used by the parser are defined here. The parser only accepts names in its syntax and so even single character symbols must be named and specified. See below for the syntax of the scanner spec. If more than one scanner spec is encountered then they will simply be concatinated in the order they are encountered as if they appeared in a single specification.
- ``%parser { parser spec }`` - This is the parser specification. This uses non-terminal and terminal symbols to define the structure of the input grammar. If multiple parser specs are encountered, then they are simply concatinated as if they all appear in the same block of definition. See below for more information about the syntax of the parser specification.

## Scanner Specification
[top](#sapcc)

The scanner is specified in one or more scanner blocks. (see above) A scanner block consists of one or more scanner rules. A scanner rule consists of an optional symbol, exactly one pattern, and a required code block. The code block is executed when then the pattern is recognized by the scanner driver. It can be used to do translations on the token that was read. One or more %code directives can be optionally embedded in the scanner section to facilitate this functionality. Rules are taken in the order they are received. Rule recogntion is "greedy" in the the longest match that is possible is the one that is taken. This implies that situations where more than one rule matches, the first one that is defined in the one that is taken to be true. For example, keywords may look like a symbol, but for the placement in the specification. This is due to the simplicity of the recognition algorithm.

```
# This is an example scanner specification with explanations of the elements.
# Comments can appear anywhere in the input file and start with a '#' and end at the new line.

# The is the general form of a scanner block.
%scanner
  %code {
    // note that this C code is copied to the beginning of the scanner source file verbatim.
    static struct some_code {
     int blabla;
    };
  }

  # These rules do not have any code defined, but the {} are still required.
  # Patterns for string literals are enclosed in "".
  PLUS: "+" {} # This defines a name of PLUS and is recognized with a "+" is seen.
  ADD_ASSIGN: "+=" {} # This defines a name of ADD_ASSIGN and is recognized with "+=" is seen.
  CLASS : "class" {} # Recognize a random keyword.

  # This rule defines a generic symbol.
  # Patterns for regular expressions are enclosed in ()
  SYMB: ([a-zA-Z_][a-zA-Z_0-9]*) {
    // Look up the name or something, or nothing at all. This code is copied to the inside
    // of the function that recognizes the pattern and it is executed as the function is
    // returning.
  }

  # This rule defines a complex number.
  # Note that every element in the expression is enclosed in a range. The range is expanded
  # and matched in order according to the rules.
  NUM: ([0-9]+[[.][0-9]+[[eE][+-]?[0-9]+]?]?) {
    // The token has a void pointer that you can use to return arbitrary information.
    token.data = allocate_obj(sizeof(double));
    *((double*)data) = strtod(token.string, NULL);
    // The symbol NUM is created by this definition and it will be the type assigned to the
    // token when the parser receives it. Notice that there are multiple patterns embedded
    // in the rule.
  }

  # This rule recognizes spaces and runs code when they are found, but does not return it
  # to the parser.
  : ([ \t\n\r]+) {
    // Line and column numbers are already tracked by the scanner.
  }

  # This rule recognizes a quoted string that includes newlines. The '.' recognizes all
  # characters that are printable but not white space. If you leave out the new lines
  # then the rule will cause a scanner error if there is no quote encountered before the
  # new line. All characters are copied to the token string, including the enclosing quotes.
  QSTR: (["][ \n\r\t.]*["]) {}

```
### Regular expressions
[top](#sapcc)

A regular expression is a construct that is capable of matching a variable character set within limits. The expression and the literal strings have to be matched together to select the proper result to return. For this scanner, regular expressions are a simplified hybrid of other implementations and instead of compiling them into a virtual environment, they are emitted as functions. The expressions are represented as one or more character ranges with an optional operator.

- ``[]`` - A character range that matches exactly one character.
- ``[]*`` - A character range that matches zero or more characters.
- ``[]+`` - A character range that matches one or more characters.
- ``[]?`` - A character range that matches zero or more characters.

A character range is defined as a group of characters.
- ``[a-z]`` - Matches exactly one of any character between 'a' and 'z' as defined by UTF-8.
- ``[a-z][0-9]+`` - Matches exactly one instance of a number prefixed with a single lower case character. For example, ``a012`` matches but ``a0a`` does not match. Also, ``a`` does not match and ``23`` does not match.
- ``[a-zA-Z_][a-zA-Z0-9_]+`` Matches a nominal symbol name.

### Scanner generator implementation
[top](#sapcc)

The scanner is a hybrid state machine. The rules are translated to C functions. The functions are kept in an array and executed in turn. If there is a possible match when a character is read, then the rule has a weight value incremented. When there are no more possible matches, then the rule with the highest weight is chosen to return. Regular expressions are implemented as individual functions where the character range is matched according to the operator.

### File stack
[top](#sapcc)

The file stack is the way that the scanner handles included files. When a file is opened as a result of an open_file() API call, the file information is pushed on a stack. All input is drawn from the top of the stack. When a file runs out, it is closed and popped from the stack and the input is drawn from the new top of stack. An ind of file notification is not returned until there is no more input to read from disk.

### Scanner tokens
[top](#sapcc)

The scanner token is the output of the scanner that the parser consumes. If the scanner fails to create a token data structure then the driver returns NULL. When the scanner finds the end of input, then it returns a dedicated token of the type END_OF_INPUT. Note that this does not mean end of file. When a file ends, it is automatically closed and popped from the file stack.

The token data structure is as follows:
```c

typedef struct {
  TokenType type;  // enum token number
  STR string;      // the string that was recognized for the token
  void* data;      // user's optional data for the token
  int line;        // line number that the token comes from
  int column;      // column number that the token was recognized from
  STR file_name;   // file name of the file that the token was in
} Token;

```

### Scanner API
[top](#sapcc)

The scanner api is not intended to be used directly, but there is no reason that it cannot be done. The scanner API is intended to be used from the parser.

```C

// Open a file and push it on the file stack. All errors are fatal.
void open_file(const char* fname);
// Cause a new token to be read from the input and make it the current token.
void consume_token();
// Returns a allocated copy of the current token. If there is no token (i.e. no open file) then
// return NULL.
const Token* get_token();

```

### Scanner errors
[top](#sapcc)

This addresses error handling that is built into the generator and the generated code.

#### Compile time errors
[top](#sapcc)

Compile time is when the scanner specification is read and processed into the data structures that will be used for further processing.

- If an input file cannot be opened, as specified on the command line or using an ``%include`` directive, then a fatal error happens.

- Any part of a rule is malformed causes a compile time error. Error recovery is attempted by reading a few characters and then trying to synchronize on a rule. If that cannot be done, then the error becomes fatal.

#### Runtime errors
Run time is when the generated scanner reads the user's input and performs the operatons that have been specified.

- An unknown character is encountered. A table is made by the scanner that identitifies all valid characters. If an input character that is not valid is encountered, then the scanner produces a non-fatal error.

- A token cannot be created from the input. This happens when the specification incorrectly specifies token, but the specification is syntatically correct. This is a fatal error because the scanner cannot continue when it happens.

## Parser Specification
[top](#sapcc)

The parser is specified in one or more parser blocks. (see above) A parser block consists of one or more parser rules. A parser rule consists of a non-terminal symbol definition that is followed by one or more patterns. When there is more than one %parser directive encountered, they are simply concatenated in the order they are seen, as if they appeared in a single specification. One or more optional %code directives can be embedded within a parser specification and the code that they contain is concatenated and added to the beginning of the parser file.

This system implements a recursive decent parser that creates a syntax tree of the user's input. That is not the same as an abstract syntax tree (AST). An abstract tree has a lot of uninteresting data removed and does a better job of capturing the actual meaning of the user's input. This parser only attempts to capture the syntax of the user's input and validate that it matches the grammar. It does not have any logic to validate that the user's input is correct other than that. The person using the parser to create a language has to add the code to validate things like whether symbols are correct and such. That is done by adding callback information to the individual rules. There are 2 ways to do that.

The output of the parser is a syntax tree data structure. The tree is implemented as a linked list of linked lists. So, each node has a list of nodes that create the tree. In addition to that, a function entry point is generated that allows the tree to be automatically traversed, visiting every node that was created by the parse. Provision is made for the user of the parser to implement a syntax-directed logic that performs the work that the parser is required to do. This particular functionality is intended to be used to create a compiler.

A block of arbitrary code can be added to the rule such that it will be run when the rule is recognized by the parser, meaning that when a non-terminal symbol is recognized, then the code will be run. Second a block of code is defined such that it is run when the syntax tree is traversed. This code is defined after the rule clause. These blocks of code can be any arbitrary code and there is no limit on the length, but it is thought that it would realistically be one or two lines where the bulk of the code is defined somewhere else. That's why the ``%code`` directives exist, but nothing says that there could be code defined in another file somewhere.

The idea is that all of the code that emits something for the compiler output will be run when the syntax tree is traversed. The code to start and traverse the syntax tree is generated by this functionality. Semantic errors that result from code that is syntatically correct will be caught and reported by logic that is not implemented by this system. Also this system does not implement the logic to emit any kind of compiler output.

```
# This is an example of a set of parser rules.
%parser
  # The code defined in this block will be placed near the beginning of the
  # generated code for the parser.
  %code {
    // This is C code that is copied without modifications to the output of
    // the compiler generator.
  }

  # This rule demonstrates a recursive list. The recursive element must be first
  # and left recursion is not supported.
  module {
      // This is C code that is embedded in a function and is called when the
      // non-terminal symbol is recognized by the generated parser.
    }
    : module_element module {
      // This is C code that is embedded in a function and is called when this
      // syntax tree node is traversed. The tokens that were recognized by the
      // parser are available as variables. For example, the syntax tree node is
      // available as $0. The module_element token data structure is available as
      // $1, and the module is available as $2. (work on this)
    }
    : module_element {
      // C code.
    }

  # This rule demonstrates that several different non-terminals can make a
  # rule.
  module_element {}
    : namespace_definition {}
    : class_definition {}
    : include_definition {}

  # This rule demonstrates an indirectly recursive rule.
  namespace_definition {}
    : NAMESPACE SYMBOL OBRACE module CBRACE {}

  # This rule demonstrates that blank rules are not allowed.
  class_definition {}
    : CLASS SYMBOL OPAREN SYMBOL CPAREN class_body {}
    : CLASS SYMBOL OPAREN CPAREN class_body {}
    : CLASS SYMBOL class_body {}

  # The scanner supports having multiple files open for inclusion.
  include_definition {}
    : INCLUDE SYMBOL {}

  # This is left empty, but that is not correct syntax. Don't want to write a whole
  # grammar in this example.
  class_body {}
    : some stuff {}

```

## Rules
[top](#sapcc)

Parser rules are fairly flexible. There are a few caviats due to the simplicity of the system.

- Blank rules are not allowed.
- Recursive rules for lists have to have a specific form. The recursive part of the has to be the first rule clause and left recursion is not supported.
- All rule clauses require a code section, even if it's empty.

### Rule structure
[top](#sapcc)

The structure of rules is simple. The first item encountered must be the unique name of a non-terminal symbol. Following that, a code block is required. This may be empty, but code that is in the block will be appended to the function that builds the syntax tree. Next, there are one or more rule clauses. Each clause starts with a colon ':', that tells the system that this is a rule clause. The clause is a list of terminal and non-terminal symbols that specify the structure of the rule. Then another code block is present that may be blank. This code block is appended to the end of the function that traverses the syntax tree. The code in the code block can access the tokens in the rule clause using symbols similar to YACC where the symbol is a pointer to the actual token.

### Accessing data inside a rule clause
[top](#sapcc)

All of the data that is generated when a rule clause is recognized is available to the code that connects the rule clause to the user's code. All of the symbols access the syntax tree node data structure, which in turn contains everything that is known about the current non-terminal that is currently being recognized. Technically, every part of the data can be accessed through the non-terminal, but additional pointers are provided for ease of access.

```c

// This is a syntax tree node. All of the syntax tree is composed of these nodes.
typedef struct {
  NodeType type;  // The type of node that this is.
  Token* token;   // If this is a terminal symbol, then this will have a non-NULL token.
  LinkList* list; // All of the elements that compose this non-terminal. NULL if it's a terminal.
  void* data;     // Arbitrary user data.
} STreeNode;

```

- ``$0`` - This is the current non-terminal node.
- ``$1`` - First element of the linked list.
- ``...`` - Any arbitrary list element. Null if the element does not exist.

Rule structure example:
```
# This is non-terminal symbol. These conform to the same rules as symbols in C.
non_terminal {
    // This code runs after the rule is recognized in the parser.
    $0->data = create_user_data();
  }
  : TERMINAL nterm1 nterm2 {
    // This code runs when the syntax tree is traversed. This code is embedded in the
    // function that handles the tree node that this rule caluse created during parsing.
    // It is intended that whatever work the compiler does is implemented by these
    // lines. Normally, there will be one or two lines given here with the rest of the
    // code implemented somewhere else. The elements in this rule clause are accessed
    // using symbols similar to YACC or Bison. See below.

    // For example:
    $0->data = update_user_data($0);
  }
# Note the absence of a symbol following the list of clauses.

```

### Parser generator implementation
[top](#sapcc)

The parser generator generates a recursive decent parser that outputs a simple syntax tree. It reads the specification that is created by the user and generates all of the functionality to read the parser's input, recognize the grammar, and output the tree. Also, the functions are generated that traverse the tree.

The input file(s) define a scanner specification that separates the input terminal symbols into tokens, and a grammar that combines the tokens into groups that are used to create the syntax tree.

First, the input file(s) are scanned and parsed into a data structure that represents the raw input. Then the data structure is traversed to output the code that implementes the actual parser and the other functionality.

If there are conflicts in the grammar, the first item encountered is taken to be correct. There is no real detection for conflicts, as it the normal case for recursive decent parsers.

### Parser errors
[top](#sapcc)

This addresses parser errors that are generated directly by the functionality.

#### Compile time errors
Compile time errors happen when the user's grammar definition is read into the system and the output code is emitted.

- File errors are handled by the scanner.
- If a rule or directive is malformed then a syntax error is generated. These errors are fatal. The file, line, and column are indicated to facilitate debugging.

#### Run time errors
Run time errors happen when the generated parser reads the user's input and attempts to generate the syntax tree from it.

- When a combination of tokens read by the scanner cannot be matched to a rule, then a syntax error is generated. These internally generated syntax error have the general form of "expected a XXX but got a YYY". They include a file name, line number, and column number to facilitate fixing the problem. After a syntax error the parser attempts to re-synchronize with the input by ignoring some number of tokens and then waiting for some particular construct. This must be defined in the context of the user's context using the ``%syntax`` directive.

- Note that semantic errors can only be detected by the user's code. This parser generator only attepmts to match the syntax to the grammar.



